# Nextflow DSL

Nextflow is a domain-specific language (DSL) for writing computational pipeline, similar to [Snakemake](https://snakemake.readthedocs.io/en/stable/) and [Apache Airflow](https://airflow.apache.org/), and superior to the conventional method using `Makefile`.
During testing, Nextflow pipelines were tested with Apptainer/Singularity SIF.
Testing was attempted with `aixnr/linken` Docker container but the environment was buggy, mainly stemming from permission issues.

```bash
apptainer exec [LINKEN.SIF_LOCATION] nextflow pipeline.nf
```

This assume the folder that this command was run in contains `raw_reads` subdirectory.
`nextflow` creates a directory called `work` where the input files are referenced by symbolic links and intermediate outputs are stored.
See `docs/building.md` for more information regarding the container.


## Generating Index Files from Reference Genome

`aixnr/linken-contrib` contains reference FASTA files for generating the index.
The process for fetching reference FASTA and generating index files is handled by `lunar` (`/usr/local/bin/lunar.py` --> `/usr/local/bin/lunar`) python utility script.


## Locating Sequencing Reads and Trimming

*Channel* is used to locate raw sequencing reads.
In particular, here we use *channel factory* with `.fromFilePairs()` method to locate paired raw sequencing reads identified by `{R1,R2}` for read 1 (i.e., `R1`) and read 2 (i.e., `R2`).
This is generally the accepted convention Illumina paired-end sequencing.

File: `map.nf`:

```groovy
process TRIM {
  publishDir "trimmed", mode: "copy"

  input:
    tuple val(sample_id), path(reads)

  output:
    path "*.fq.gz"

    script:
    """
    trimgalore --paired \
      ${reads[0]} ${reads[1]}
    """
}

ch_raw_reads = channel.fromFilePairs("raw_reads/*_{R1,R2}_*.fastq.gz")

workflow {
  TRIM(ch_raw_reads)
}
```

To run: `apptainer exec [LINKEN.SIF_LOCATION] nextflow map.nf`.

The `publishDir` directory directive tells `nextflow` to publish the output `*.fq.gz` into `$(pwd)/trimmed` directory. Otherwise, the trimmed sequences are still produced by tucked away inside the `$(pwd)/work` directory.


## Chaining from Trimmed Sequence to Mapping

File: `map.nf`

Assuming current `$(PWD)` has `raw_reads` and `index` directories, which also assumes the index files were already generated by `lunar create` command.
Two directories are generated for the pipeline artifacts: `report` and `data`.

```groovy
ch_raw_reads = channel.fromFilePairs("raw_reads/*_{R1,R2}_*.fastq.gz")
bwa_index = "$projectDir/index/ref"

workflow {
  QC_REPORT(ch_raw_reads)
  TRIM(ch_raw_reads)
  MAP( TRIM.out )
  COVERAGE( MAP.out )
  GENERATE_BAI( MAP.out )
}

process QC_REPORT {
  publishDir "report/fastqc", mode: "copy"

  input:
    tuple val(sample_id), path(reads)
  
  output:
    path("*.html")

  script:
  """
  fastqc ${reads[0]} ${reads[1]}
  """
}

process TRIM {
  input:
    tuple val(sample_id), path(reads)

  output:
    tuple val(sample_id), path("*.fq.gz")
  
  script:
  """
  trimgalore --paired ${reads[0]} ${reads[1]}
  """
}

process MAP {
  publishDir "data/alignment", mode: "copy"

  input:
    tuple val(sample_id), path(reads)

  output:
    tuple val(sample_id), path("*.bwa.bam")

  script:
  """
  bwa mem -M ${bwa_index} ${reads[0]} ${reads[1]} | \
    samtools view --bam | \
    samtools sort -o ${sample_id}.bwa.bam
  """
}

process COVERAGE {
  publishDir "report/coverage", mode: "copy"

  input:
    tuple val(sample_id), path(bwa)
  
  output:
    path("*.tsv")

  shell:
  '''
  samtools mpileup !{bwa} --fasta-ref !{bwa_index}.fasta | \
    awk '{print $1"\t"$2"\t"$3"\t"$4}' > !{bwa}_coverage.tsv
  '''
}

process GENERATE_BAI {
  publishDir "data/alignment", mode: "copy"

  input:
    tuple val(sample_id), path(bwa)
  
  output:
    path("*.bai")

  script:
  """
  samtools index ${bwa}
  """
}
```

